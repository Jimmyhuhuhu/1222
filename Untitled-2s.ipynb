{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: not using Google CoLab\n",
      "Requirement already satisfied: kaleido in c:\\users\\garyhu\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (0.2.1)\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive', force_remount=True)\n",
    "    COLAB = True\n",
    "    print(\"Note: using Google CoLab\")\n",
    "except:\n",
    "    print(\"Note: not using Google CoLab\")\n",
    "    COLAB = False\n",
    "\n",
    "PATH = '/content/drive/MyDrive'\n",
    "\n",
    "! pip install -U kaleido\n",
    "\n",
    "# Configuration\n",
    "FPS = 30\n",
    "FFT_WINDOW_SECONDS = 0.25 # how many seconds of audio make up an FFT window\n",
    "\n",
    "# Note range to display\n",
    "FREQ_MIN = 10\n",
    "FREQ_MAX = 1000\n",
    "\n",
    "# Notes to display\n",
    "TOP_NOTES = 3\n",
    "\n",
    "# Names of the notes\n",
    "NOTE_NAMES = [\"C\", \"C#\", \"D\", \"D#\", \"E\", \"F\", \"F#\", \"G\", \"G#\", \"A\", \"A#\", \"B\"]\n",
    "\n",
    "# Output size. Generally use SCALE for higher res, unless you need a non-standard aspect ratio.\n",
    "RESOLUTION = (1920, 1080)\n",
    "SCALE = 2 # 0.5=QHD(960x540), 1=HD(1920x1080), 2=4K(3840x2160)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/content/drive/MyDrive\\\\music.wav'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 13\u001b[0m\n\u001b[0;32m      7\u001b[0m AUDIO_FILE \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(PATH,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmusic.wav\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# Or download my sample audio\u001b[39;00m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# !wget https://github.com/jeffheaton/present/raw/master/youtube/video/sample_audio/piano_c_major_scale.wav\u001b[39;00m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# AUDIO_FILE = \"/content/piano_c_major_scale.wav\"\u001b[39;00m\n\u001b[1;32m---> 13\u001b[0m fs, data \u001b[38;5;241m=\u001b[39m \u001b[43mwavfile\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mAUDIO_FILE\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# load the data\u001b[39;00m\n\u001b[0;32m     14\u001b[0m audio \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mT[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;66;03m# this is a two channel soundtrack, get the first track\u001b[39;00m\n\u001b[0;32m     15\u001b[0m FRAME_STEP \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(fs \u001b[38;5;241m/\u001b[39m FPS) \u001b[38;5;66;03m# audio samples per video frame\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\garyhu\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\io\\wavfile.py:647\u001b[0m, in \u001b[0;36mread\u001b[1;34m(filename, mmap)\u001b[0m\n\u001b[0;32m    645\u001b[0m     mmap \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    646\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 647\u001b[0m     fid \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    649\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    650\u001b[0m     file_size, is_big_endian \u001b[38;5;241m=\u001b[39m _read_riff_chunk(fid)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/drive/MyDrive\\\\music.wav'"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from scipy.fftpack import fft\n",
    "from scipy.io import wavfile # get the api\n",
    "import os\n",
    "\n",
    "# Get a WAV file from GDrive, such as:\n",
    "AUDIO_FILE = os.path.join(PATH,'music.wav')\n",
    "\n",
    "# Or download my sample audio\n",
    "# !wget https://github.com/jeffheaton/present/raw/master/youtube/video/sample_audio/piano_c_major_scale.wav\n",
    "# AUDIO_FILE = \"/content/piano_c_major_scale.wav\"\n",
    "\n",
    "fs, data = wavfile.read(AUDIO_FILE) # load the data\n",
    "audio = data.T[0] # this is a two channel soundtrack, get the first track\n",
    "FRAME_STEP = int(fs / FPS) # audio samples per video frame\n",
    "FFT_WINDOW_SIZE = int(fs * FFT_WINDOW_SECONDS)\n",
    "AUDIO_LENGTH = len(data) / fs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "\n",
    "def plot_fft(p, xf, fs, notes, dimensions=(960,540)):\n",
    "  layout = go.Layout(\n",
    "      title=\"frequency spectrum\",\n",
    "      autosize=False,\n",
    "      width=dimensions[0],\n",
    "      height=dimensions[1],\n",
    "      xaxis_title=\"Frequency (note)\",\n",
    "      yaxis_title=\"Magnitude\",\n",
    "      font={'size' : 24}\n",
    "  )\n",
    "\n",
    "  fig = go.Figure(layout=layout,\n",
    "                  layout_xaxis_range=[FREQ_MIN,FREQ_MAX],\n",
    "                  layout_yaxis_range=[0,1]\n",
    "                  )\n",
    "\n",
    "  fig.add_trace(go.Scatter(\n",
    "      x = xf,\n",
    "      y = p))\n",
    "\n",
    "  for note in notes:\n",
    "    fig.add_annotation(x=note[0]+10, y=note[2],\n",
    "            text=note[1],\n",
    "            font = {'size' : 48},\n",
    "            showarrow=False)\n",
    "  return fig\n",
    "\n",
    "def extract_sample(audio, frame_number):\n",
    "    end = frame_number * FRAME_OFFSET\n",
    "    begin = int(end - FFT_WINDOW_SIZE)\n",
    "\n",
    "    if end <= 0:\n",
    "        # We have no audio yet, return all zeros (very beginning)\n",
    "        return np.zeros(FFT_WINDOW_SIZE, dtype=float)\n",
    "    elif begin < 0:\n",
    "        # We have some audio, pad with zeros\n",
    "        padded_audio = np.concatenate([np.zeros(abs(begin), dtype=float), data[:end]])\n",
    "        return padded_audio[-FFT_WINDOW_SIZE:]\n",
    "    else:\n",
    "        # Usually this happens, return the next sample\n",
    "        return audio[begin:end]\n",
    "\n",
    "\n",
    "def find_top_notes(fft,num):\n",
    "  if np.max(fft.real)<0.001:\n",
    "    return []\n",
    "\n",
    "  lst = [x for x in enumerate(fft.real)]\n",
    "  lst = sorted(lst, key=lambda x: x[1],reverse=True)\n",
    "\n",
    "  idx = 0\n",
    "  found = []\n",
    "  found_note = set()\n",
    "  while( (idx<len(lst)) and (len(found)<num) ):\n",
    "    f = xf[lst[idx][0]]\n",
    "    y = lst[idx][1]\n",
    "    n = freq_to_number(f)\n",
    "    n0 = int(round(n))\n",
    "    name = note_name(n0)\n",
    "\n",
    "    if name not in found_note:\n",
    "      found_note.add(name)\n",
    "      s = [f,note_name(n0),y]\n",
    "      found.append(s)\n",
    "    idx += 1\n",
    "\n",
    "  return found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tqdm\n",
    "\n",
    "# ! rm /content/*.png\n",
    "\n",
    "# See https://newt.phys.unsw.edu.au/jw/notes.html\n",
    "def freq_to_number(f): return 69 + 12*np.log2(f/440.0)\n",
    "def number_to_freq(n): return 440 * 2.0**((n-69)/12.0)\n",
    "def note_name(n): return NOTE_NAMES[n % 12] + str(int(n/12 - 1))\n",
    "\n",
    "# Hanning window function\n",
    "window = 0.5 * (1 - np.cos(np.linspace(0, 2*np.pi, FFT_WINDOW_SIZE, False)))\n",
    "\n",
    "xf = np.fft.rfftfreq(FFT_WINDOW_SIZE, 1/fs)\n",
    "FRAME_COUNT = int(AUDIO_LENGTH*FPS)\n",
    "FRAME_OFFSET = int(len(data)/FRAME_COUNT)\n",
    "\n",
    "# Pass 1, find out the maximum amplitude so we can scale.\n",
    "mx = 0\n",
    "data = np.mean(data, axis=1)\n",
    "\n",
    "for frame_number in range(FRAME_COUNT):\n",
    "  sample = extract_sample(data, frame_number)\n",
    "\n",
    "  fft = np.fft.rfft(sample * window)\n",
    "  fft = np.abs(fft).real\n",
    "  mx = max(np.max(fft),mx)\n",
    "\n",
    "print(f\"Max amplitude: {mx}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def freq_to_number(f):\n",
    "    if f == 0:\n",
    "        return float('-inf')  # 处理频率为0的情况，避免除以零错误\n",
    "    else:\n",
    "        return 69 + 12*np.log2(f/440.0)\n",
    "\n",
    "def find_top_notes(fft, num):\n",
    "    if np.max(fft.real) < 0.001:\n",
    "        return []\n",
    "\n",
    "    lst = [x for x in enumerate(fft.real)]\n",
    "    lst = sorted(lst, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    idx = 0\n",
    "    found = []\n",
    "    found_note = set()\n",
    "    while idx < len(lst) and len(found) < num:\n",
    "        f = xf[lst[idx][0]]\n",
    "        y = lst[idx][1]\n",
    "        n = freq_to_number(f)\n",
    "        if np.isfinite(n):  # 检查n是否为有限值，避免溢出错误\n",
    "            n0 = int(round(n))\n",
    "            name = note_name(n0)\n",
    "            if name not in found_note:\n",
    "                found_note.add(name)\n",
    "                s = [f, name, y]\n",
    "                found.append(s)\n",
    "        idx += 1\n",
    "\n",
    "    return found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for frame_number in tqdm.tqdm(range(FRAME_COUNT)):\n",
    "    sample = extract_sample(data, frame_number)\n",
    "\n",
    "    fft = np.fft.rfft(sample * window)\n",
    "\n",
    "    # 检查fft是否全为零，避免在计算mx时出现除以零错误\n",
    "    if np.all(fft == 0):\n",
    "        continue\n",
    "\n",
    "    fft = np.abs(fft) / mx\n",
    "\n",
    "    # 检查fft是否包含无穷大或无穷小的情况，避免在调用find_top_notes函数时出现异常\n",
    "    if np.any(np.isinf(fft)) or np.any(np.isnan(fft)):\n",
    "        continue\n",
    "\n",
    "    s = find_top_notes(fft, TOP_NOTES)\n",
    "\n",
    "    fig = plot_fft(fft.real, xf, fs, s, RESOLUTION)\n",
    "    # fig.write_image(f\"/content/frame{frame_number}.png\", scale=2)\n",
    "    fig.write_image(f\"/content/frame{frame_number}.png\", scale=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ffmpeg -y -r {FPS} -f image2 -s 1920x1080 -i frame%d.png -i {AUDIO_FILE} -c:v libx264 -pix_fmt yuv420p movie.mp4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "files.download('movie.mp4')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
